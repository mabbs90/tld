{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dropout, Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "import pathlib\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for real data\n",
    "shutil.rmtree('./data/train')\n",
    "shutil.rmtree('./data/test')\n",
    "pathlib.Path('./data/train').mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path('./data/test').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "classes = ['green', 'red', 'unidentified']\n",
    "\n",
    "for j in np.arange(len(classes)):\n",
    "    cls = classes[j]\n",
    "    \n",
    "    print('processing class ' + cls + '\\n')\n",
    "\n",
    "    pathlib.Path('./data/train/'+ cls).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path('./data/test/' + cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    path = './data/real_training_data/' + cls + '/'\n",
    "    files = os.listdir(path)\n",
    "    train_indx = np.random.choice(len(files), np.int(np.floor(len(files) * 0.7)), replace = False)\n",
    "    test_indx = list(set(np.arange(len(files))) - set(train_indx))\n",
    "    print(len(train_indx))\n",
    "    print(len(test_indx))\n",
    "    print(len(files))\n",
    "\n",
    "    for i in np.arange(len(train_indx)):\n",
    "        indx = train_indx[i]\n",
    "        file = files[indx]\n",
    "        src = path + file\n",
    "        dest = './data/train/' + cls + '/' + file\n",
    "        copyfile(src, dest)\n",
    "    for i in np.arange(len(test_indx)):\n",
    "        indx = test_indx[i]\n",
    "        file = files[indx]\n",
    "        src = path + file\n",
    "        dest = './data/test/' + cls + '/' + file\n",
    "        copyfile(src, dest)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for simulation data -- append to previous\n",
    "classes = ['green', 'red', 'unidentified']\n",
    "\n",
    "for j in np.arange(len(classes)):\n",
    "    cls = classes[j]\n",
    "    \n",
    "    print('processing class ' + cls + '\\n')\n",
    "\n",
    "    path = './data/sim_data_capture/' + cls + '/'\n",
    "    files = os.listdir(path)\n",
    "    train_indx = np.random.choice(len(files), np.int(np.floor(len(files) * 0.7)), replace = False)\n",
    "    test_indx = list(set(np.arange(len(files))) - set(train_indx))\n",
    "    print(len(train_indx))\n",
    "    print(len(test_indx))\n",
    "    print(len(files))\n",
    "\n",
    "    for i in np.arange(len(train_indx)):\n",
    "        indx = train_indx[i]\n",
    "        file = files[indx]\n",
    "        src = path + file\n",
    "        dest = './data/train/' + cls + '/' + 'sim_' + file\n",
    "        copyfile(src, dest)\n",
    "    for i in np.arange(len(test_indx)):\n",
    "        indx = test_indx[i]\n",
    "        file = files[indx]\n",
    "        src = path + file\n",
    "        dest = './data/test/' + cls + '/' + 'sim_' + file\n",
    "        copyfile(src, dest)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, ELU\n",
    "from keras.layers import Input, Activation, Dropout, merge\n",
    "from keras.layers import Cropping2D, Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "def Inception(layer, inner_depth, out_depth, activation):\n",
    "\n",
    "    conv_1x1_1 = Convolution2D(out_depth, 1, 1, border_mode = 'same')(layer)\n",
    "\n",
    "    conv_3x3 = Convolution2D(inner_depth, 1, 1, border_mode = 'same', activation = 'relu')(layer)\n",
    "    conv_3x3 = Convolution2D(out_depth, 3, 3, border_mode = 'same')(conv_3x3)\n",
    "\n",
    "    conv_5x5 = Convolution2D(inner_depth, 1, 1, border_mode = 'same', activation = 'relu')(layer)\n",
    "    conv_5x5 = Convolution2D(out_depth, 5, 5, border_mode = 'same')(conv_5x5)\n",
    "\n",
    "    conv_1x1_4 = MaxPooling2D((3, 3), strides = (1, 1), border_mode = 'same')(layer)\n",
    "    conv_1x1_4 = Convolution2D(out_depth, 1, 1, border_mode = 'same')(conv_1x1_4)\n",
    "\n",
    "    output = merge([conv_1x1_1, conv_3x3, conv_5x5, conv_1x1_4], concat_axis = 1)\n",
    "\n",
    "    output = Activation(activation)(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def toy2():\n",
    "    \n",
    "    activation = 'relu'\n",
    "    input_shape = (64, 64, 3)\n",
    "    \n",
    "    inp = Input(shape = input_shape)\n",
    "    net = Convolution2D(32, 3, 3, border_mode = 'same')(inp)\n",
    "    net = Activation(activation)(net)\n",
    "    net = Convolution2D(32, 3, 3, border_mode = 'same')(net)\n",
    "    net = Activation(activation)(net)\n",
    "    net = MaxPooling2D((2, 2), strides = (2, 2))(net)\n",
    "    net = Dropout(0.8)(net) \n",
    "   \n",
    "    net = Inception(net, 32, 16, activation)\n",
    "\n",
    "\n",
    "    net = Convolution2D(64, 3, 3, border_mode = 'same')(inp)\n",
    "    net = Activation(activation)(net)\n",
    "    net = Convolution2D(64, 3, 3, border_mode = 'same')(net)\n",
    "    net = Activation(activation)(net)\n",
    "    net = MaxPooling2D((2, 2), strides = (2, 2))(net)\n",
    "    net = Dropout(0.6)(net) \n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    net = Dense(512)(net)\n",
    "    net = Activation(activation)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = Dense(3)(net)\n",
    "    net = Activation('softmax')(net)\n",
    "    \n",
    "    return inp, net\n",
    "\n",
    "inp, net = toy2()\n",
    "model = Model(inp, net)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dirr = './data/train'\n",
    "classes = ['unidentified', 'green', 'red']\n",
    "\n",
    "batch_size = 64\n",
    "nb_epoch = 10\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=.2, \n",
    "                             height_shift_range=.2, \n",
    "                             shear_range=0.05, \n",
    "                             zoom_range=.1,\n",
    "                             fill_mode='nearest', \n",
    "                             rescale=1. / 255)\n",
    "image_data_gen = datagen.flow_from_directory(dirr, \n",
    "                                             target_size=(64, 64), \n",
    "                                             classes=classes,\n",
    "                                             batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(image_data_gen, nb_epoch=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## prediction\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def reshape_image(img):\n",
    "  img = cv2.resize(img, (64, 64)) \n",
    "  x = img_to_array(img)\n",
    "  return x[None, :]\n",
    "\n",
    "classes = image_data_gen.class_indices\n",
    "\n",
    "\n",
    "path = './data/test/'\n",
    "\n",
    "right = 0\n",
    "wrong = 0\n",
    "for i in ['green', 'red', 'unidentified']:\n",
    "    files = os.listdir(path + i)\n",
    "    for j in np.arange(len(files)):\n",
    "        imgpath = path + i + '/' + files[j]\n",
    "        img = cv2.imread(imgpath)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ## plt.imshow(img)\n",
    "        ## img.shape\n",
    "        probs = model.predict(reshape_image(img))\n",
    "        max_prob = probs.argmax(axis = -1)\n",
    "        predicted_class = list(classes.keys())[list(classes.values()).index(max_prob[0])] \n",
    "        \n",
    "        if predicted_class == i:\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1  \n",
    "            \n",
    "print(right)\n",
    "print(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
